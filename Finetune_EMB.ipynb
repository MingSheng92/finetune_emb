{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "966f42b2-9460-408d-85cf-fba81b024946",
   "metadata": {},
   "source": [
    "## Fine-tune Embedding model for RAG "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca1bbd4-204f-4869-8904-57b42a3ff8af",
   "metadata": {},
   "source": [
    "In some of my previous projects with LLM/Gen AI, I often have to utlize embbeding models for RAG use case. It is a important component for RAG but they are often trained on general knowledge, which may hinder the performance for domain specific use case. By fine-tuning the embedding model we can boost the retrieval capability of RAG application. So in this notebook, I would like to explore how to fine tune embedding models with Sentence Transformers 3. \n",
    "\n",
    "Today, we would like to explore on fine-tuning an embeddingmodel for financial RAG application using synthetic dataset from SEC filling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2c698ed-396d-4ba1-bdd5-94306ae8d407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1324af3e5b3e4d9ea5b8259f253c8db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08dcedf755114799af809707b5dfe3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "240104"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    " \n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(\"source_data/finanical-rag-embedding-dataset\", split=\"train\")\n",
    " \n",
    "# rename columns\n",
    "dataset = dataset.rename_column(\"question\", \"anchor\")\n",
    "dataset = dataset.rename_column(\"context\", \"positive\")\n",
    " \n",
    "# Add an id column to the dataset\n",
    "dataset = dataset.add_column(\"id\", range(len(dataset)))\n",
    " \n",
    "# split dataset into a 10% test set\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    " \n",
    "# save datasets to disk\n",
    "dataset[\"train\"].to_json(\"training_data/train_dataset.json\", orient=\"records\")\n",
    "dataset[\"test\"].to_json(\"training_data/test_dataset.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b035756-e378-4732-bd26-1023c02c1d6f",
   "metadata": {},
   "source": [
    "### Create baseline and evaluate pretrained model\n",
    "\n",
    "Today, we will use the BAAI/bge-base-en-v1.5 embedding model as our baseline and fine-tuned model. with only 109M parameters and a hidden dimension of 768 it achieves 63.55 on the MTEB Leaderboard.\n",
    "\n",
    "We are going to use the InformationRetrievalEvaluator to evaluate the performance of our model on a given set of queries and corpus set. It will retrieve for each query the top-k most similar document. It measures Mean Reciprocal Rank (MRR), Recall@k, Mean Average Precision (MAP) and Normalized Discounted Cumulative Gain (NDCG).\n",
    "\n",
    "For us the most important metric will be Normalized Discounted Cumulative Gain (NDCG) as it is a measure of ranking quality. It takes into account the position of the relevant document in the ranking and discounts it. The discounted value is logarithmic, which means that relevant documents are more important if they are ranked higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cac209c-efd6-420d-9388-d2806b4ccf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "binary_path: C:\\Users\\ms\\.conda\\envs\\playground\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll\n",
      "CUDA SETUP: Loading binary C:\\Users\\ms\\.conda\\envs\\playground\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18da54236e44043b3f8d79a17e49932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5fa537258342aa8292788e177e6e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import (\n",
    "    InformationRetrievalEvaluator,\n",
    "    SequentialEvaluator,\n",
    ")\n",
    "from sentence_transformers.util import cos_sim\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    " \n",
    "model_id = \"models/bge-base-en-v1.5\"  # Hugging Face model ID\n",
    "matryoshka_dimensions = [768, 512, 256, 128, 64] # Important: large to small\n",
    " \n",
    "# Load a model\n",
    "model = SentenceTransformer(\n",
    "    model_id, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    " \n",
    "# load test dataset\n",
    "test_dataset = load_dataset(\"json\", data_files=\"training_data/test_dataset.json\", split=\"train\")\n",
    "train_dataset = load_dataset(\"json\", data_files=\"training_data/train_dataset.json\", split=\"train\")\n",
    "corpus_dataset = concatenate_datasets([train_dataset, test_dataset])\n",
    " \n",
    "# Convert the datasets to dictionaries\n",
    "corpus = dict(\n",
    "    zip(corpus_dataset[\"id\"], corpus_dataset[\"positive\"])\n",
    ")  # Our corpus (cid => document)\n",
    "queries = dict(\n",
    "    zip(test_dataset[\"id\"], test_dataset[\"anchor\"])\n",
    ")  # Our queries (qid => question)\n",
    " \n",
    "# Create a mapping of relevant document (1 in our case) for each query\n",
    "relevant_docs = {}  # Query ID to relevant documents (qid => set([relevant_cids])\n",
    "for q_id in queries:\n",
    "    relevant_docs[q_id] = [q_id]\n",
    " \n",
    " \n",
    "matryoshka_evaluators = []\n",
    "# Iterate over the different dimensions\n",
    "for dim in matryoshka_dimensions:\n",
    "    ir_evaluator = InformationRetrievalEvaluator(\n",
    "        queries=queries,\n",
    "        corpus=corpus,\n",
    "        relevant_docs=relevant_docs,\n",
    "        name=f\"dim_{dim}\",\n",
    "        truncate_dim=dim,  # Truncate the embeddings to a certain dimension\n",
    "        score_functions={\"cosine\": cos_sim},\n",
    "    )\n",
    "    matryoshka_evaluators.append(ir_evaluator)\n",
    " \n",
    "# Create a sequential evaluator\n",
    "evaluator = SequentialEvaluator(matryoshka_evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17286d35-aa27-457b-a401-b4b999d0e3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_768_cosine_ndcg@10: 0.7409673938572789\n",
      "dim_512_cosine_ndcg@10: 0.7402734381724596\n",
      "dim_256_cosine_ndcg@10: 0.7254025778084061\n",
      "dim_128_cosine_ndcg@10: 0.7051838302702277\n",
      "dim_64_cosine_ndcg@10: 0.6375033504202162\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = evaluator(model)\n",
    " \n",
    "# # COMMENT IN for full results\n",
    "# print(results)\n",
    " \n",
    "# Print the main score\n",
    "for dim in matryoshka_dimensions:\n",
    "    key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "    print\n",
    "    print(f\"{key}: {results[key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f43083-ab9f-4287-9372-f4b3f3b33dbf",
   "metadata": {},
   "source": [
    "Lets reload our model using SDPA or Flash Attention 2 as attn_implementation and define a model card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86335c57-2adb-4f3c-86dd-19e6ee563d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerModelCardData, SentenceTransformer\n",
    " \n",
    "# Hugging Face model ID: https://huggingface.co/BAAI/bge-base-en-v1.5\n",
    "model_id = \"models/bge-base-en-v1.5\"\n",
    " \n",
    "# load model with SDPA for using Flash Attention 2\n",
    "model = SentenceTransformer(\n",
    "    model_id,\n",
    "    model_kwargs={\"attn_implementation\": \"sdpa\"},\n",
    "    model_card_data=SentenceTransformerModelCardData(\n",
    "        language=\"en\",\n",
    "        license=\"apache-2.0\",\n",
    "        model_name=\"BGE base Financial Matryoshka\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140ac015-3359-4507-8daf-c6db18ff8235",
   "metadata": {},
   "source": [
    "Once loaded our model we can initialize our loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91629bdf-1ae2-4d2a-bf86-7f7669580c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
    " \n",
    "matryoshka_dimensions = [768, 512, 256, 128, 64]\n",
    "inner_train_loss = MultipleNegativesRankingLoss(model)\n",
    "train_loss = MatryoshkaLoss(\n",
    "    model, inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82f666e-f83c-4cf5-8794-6ce23532b1cc",
   "metadata": {},
   "source": [
    "### Fine-tune embedding model with SentenceTransformersTrainer\n",
    "\n",
    "We are now ready to fine-tune our model. We will use the SentenceTransformersTrainer a subclass of the Trainer from the transformers library, which supports all the same features, including logging, evaluation, and checkpointing.\n",
    "\n",
    "In addition to this there is a SentenceTransformerTrainingArguments class that allows us to specify all the training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a6886a-0759-4744-b397-a908f5da9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    " \n",
    "# load train dataset again\n",
    "train_dataset = load_dataset(\"json\", data_files=\"training_data/train_dataset.json\", split=\"train\")\n",
    " \n",
    "# define training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"finetuned_emb\", # output directory and hugging face model ID\n",
    "    num_train_epochs=4,                         # number of epochs\n",
    "    per_device_train_batch_size=32,             # train batch size\n",
    "    gradient_accumulation_steps=16,             # for a global batch size of 512\n",
    "    per_device_eval_batch_size=16,              # evaluation batch size\n",
    "    warmup_ratio=0.1,                           # warmup ratio\n",
    "    learning_rate=2e-5,                         # learning rate, 2e-5 is a good value\n",
    "    lr_scheduler_type=\"cosine\",                 # use constant learning rate scheduler\n",
    "    optim=\"adamw_torch_fused\",                  # use fused adamw optimizer\n",
    "    tf32=True,                                  # use tf32 precision\n",
    "    bf16=True,                                  # use bf16 precision\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    eval_strategy=\"epoch\",                      # evaluate after each epoch\n",
    "    save_strategy=\"epoch\",                      # save after each epoch\n",
    "    logging_steps=10,                           # log every 10 steps\n",
    "    save_total_limit=3,                         # save only the last 3 models\n",
    "    load_best_model_at_end=True,                # load the best model when training ends\n",
    "    metric_for_best_model=\"eval_dim_128_cosine_ndcg@10\",  # Optimizing for the best ndcg@10 score for the 128 dimension\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18afc860-e43d-484f-b289-9f438d119a97",
   "metadata": {},
   "source": [
    "We now have every building block we need to create our SentenceTransformersTrainer to start then training our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e23589e-340f-48f2-9615-ecfa1141a1a7",
   "metadata": {},
   "source": [
    "Make sure your library is updated for : accelerate-0.27.2\n",
    "\n",
    "https://github.com/huggingface/transformers/issues/29216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ebdef25-563b-4c8d-ba78-2572b83ee185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer\n",
    " \n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model, # bg-base-en-v1\n",
    "    args=args,  # training arguments\n",
    "    train_dataset=train_dataset.select_columns(\n",
    "        [\"positive\", \"anchor\"]\n",
    "    ),  # training dataset\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2d376ff-a650-4295-9852-2e2f688ef206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 02:53, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dim 768 Cosine Accuracy@1</th>\n",
       "      <th>Dim 768 Cosine Accuracy@3</th>\n",
       "      <th>Dim 768 Cosine Accuracy@5</th>\n",
       "      <th>Dim 768 Cosine Accuracy@10</th>\n",
       "      <th>Dim 768 Cosine Precision@1</th>\n",
       "      <th>Dim 768 Cosine Precision@3</th>\n",
       "      <th>Dim 768 Cosine Precision@5</th>\n",
       "      <th>Dim 768 Cosine Precision@10</th>\n",
       "      <th>Dim 768 Cosine Recall@1</th>\n",
       "      <th>Dim 768 Cosine Recall@3</th>\n",
       "      <th>Dim 768 Cosine Recall@5</th>\n",
       "      <th>Dim 768 Cosine Recall@10</th>\n",
       "      <th>Dim 768 Cosine Ndcg@10</th>\n",
       "      <th>Dim 768 Cosine Mrr@10</th>\n",
       "      <th>Dim 768 Cosine Map@100</th>\n",
       "      <th>Dim 512 Cosine Accuracy@1</th>\n",
       "      <th>Dim 512 Cosine Accuracy@3</th>\n",
       "      <th>Dim 512 Cosine Accuracy@5</th>\n",
       "      <th>Dim 512 Cosine Accuracy@10</th>\n",
       "      <th>Dim 512 Cosine Precision@1</th>\n",
       "      <th>Dim 512 Cosine Precision@3</th>\n",
       "      <th>Dim 512 Cosine Precision@5</th>\n",
       "      <th>Dim 512 Cosine Precision@10</th>\n",
       "      <th>Dim 512 Cosine Recall@1</th>\n",
       "      <th>Dim 512 Cosine Recall@3</th>\n",
       "      <th>Dim 512 Cosine Recall@5</th>\n",
       "      <th>Dim 512 Cosine Recall@10</th>\n",
       "      <th>Dim 512 Cosine Ndcg@10</th>\n",
       "      <th>Dim 512 Cosine Mrr@10</th>\n",
       "      <th>Dim 512 Cosine Map@100</th>\n",
       "      <th>Dim 256 Cosine Accuracy@1</th>\n",
       "      <th>Dim 256 Cosine Accuracy@3</th>\n",
       "      <th>Dim 256 Cosine Accuracy@5</th>\n",
       "      <th>Dim 256 Cosine Accuracy@10</th>\n",
       "      <th>Dim 256 Cosine Precision@1</th>\n",
       "      <th>Dim 256 Cosine Precision@3</th>\n",
       "      <th>Dim 256 Cosine Precision@5</th>\n",
       "      <th>Dim 256 Cosine Precision@10</th>\n",
       "      <th>Dim 256 Cosine Recall@1</th>\n",
       "      <th>Dim 256 Cosine Recall@3</th>\n",
       "      <th>Dim 256 Cosine Recall@5</th>\n",
       "      <th>Dim 256 Cosine Recall@10</th>\n",
       "      <th>Dim 256 Cosine Ndcg@10</th>\n",
       "      <th>Dim 256 Cosine Mrr@10</th>\n",
       "      <th>Dim 256 Cosine Map@100</th>\n",
       "      <th>Dim 128 Cosine Accuracy@1</th>\n",
       "      <th>Dim 128 Cosine Accuracy@3</th>\n",
       "      <th>Dim 128 Cosine Accuracy@5</th>\n",
       "      <th>Dim 128 Cosine Accuracy@10</th>\n",
       "      <th>Dim 128 Cosine Precision@1</th>\n",
       "      <th>Dim 128 Cosine Precision@3</th>\n",
       "      <th>Dim 128 Cosine Precision@5</th>\n",
       "      <th>Dim 128 Cosine Precision@10</th>\n",
       "      <th>Dim 128 Cosine Recall@1</th>\n",
       "      <th>Dim 128 Cosine Recall@3</th>\n",
       "      <th>Dim 128 Cosine Recall@5</th>\n",
       "      <th>Dim 128 Cosine Recall@10</th>\n",
       "      <th>Dim 128 Cosine Ndcg@10</th>\n",
       "      <th>Dim 128 Cosine Mrr@10</th>\n",
       "      <th>Dim 128 Cosine Map@100</th>\n",
       "      <th>Dim 64 Cosine Accuracy@1</th>\n",
       "      <th>Dim 64 Cosine Accuracy@3</th>\n",
       "      <th>Dim 64 Cosine Accuracy@5</th>\n",
       "      <th>Dim 64 Cosine Accuracy@10</th>\n",
       "      <th>Dim 64 Cosine Precision@1</th>\n",
       "      <th>Dim 64 Cosine Precision@3</th>\n",
       "      <th>Dim 64 Cosine Precision@5</th>\n",
       "      <th>Dim 64 Cosine Precision@10</th>\n",
       "      <th>Dim 64 Cosine Recall@1</th>\n",
       "      <th>Dim 64 Cosine Recall@3</th>\n",
       "      <th>Dim 64 Cosine Recall@5</th>\n",
       "      <th>Dim 64 Cosine Recall@10</th>\n",
       "      <th>Dim 64 Cosine Ndcg@10</th>\n",
       "      <th>Dim 64 Cosine Mrr@10</th>\n",
       "      <th>Dim 64 Cosine Map@100</th>\n",
       "      <th>Sequential Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.536400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.808571</td>\n",
       "      <td>0.844286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.269524</td>\n",
       "      <td>0.168857</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.808571</td>\n",
       "      <td>0.844286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.786060</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.756029</td>\n",
       "      <td>0.675714</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.891429</td>\n",
       "      <td>0.675714</td>\n",
       "      <td>0.264286</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.089143</td>\n",
       "      <td>0.675714</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.891429</td>\n",
       "      <td>0.783200</td>\n",
       "      <td>0.748519</td>\n",
       "      <td>0.752719</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.798571</td>\n",
       "      <td>0.834286</td>\n",
       "      <td>0.877143</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.266190</td>\n",
       "      <td>0.166857</td>\n",
       "      <td>0.087714</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.798571</td>\n",
       "      <td>0.834286</td>\n",
       "      <td>0.877143</td>\n",
       "      <td>0.774768</td>\n",
       "      <td>0.741865</td>\n",
       "      <td>0.746703</td>\n",
       "      <td>0.655714</td>\n",
       "      <td>0.782857</td>\n",
       "      <td>0.812857</td>\n",
       "      <td>0.872857</td>\n",
       "      <td>0.655714</td>\n",
       "      <td>0.260952</td>\n",
       "      <td>0.162571</td>\n",
       "      <td>0.087286</td>\n",
       "      <td>0.655714</td>\n",
       "      <td>0.782857</td>\n",
       "      <td>0.812857</td>\n",
       "      <td>0.872857</td>\n",
       "      <td>0.762759</td>\n",
       "      <td>0.727854</td>\n",
       "      <td>0.732875</td>\n",
       "      <td>0.617143</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>0.617143</td>\n",
       "      <td>0.247619</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.083571</td>\n",
       "      <td>0.617143</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>0.726284</td>\n",
       "      <td>0.691228</td>\n",
       "      <td>0.696668</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.640800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.698571</td>\n",
       "      <td>0.818571</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.898571</td>\n",
       "      <td>0.698571</td>\n",
       "      <td>0.272857</td>\n",
       "      <td>0.170286</td>\n",
       "      <td>0.089857</td>\n",
       "      <td>0.698571</td>\n",
       "      <td>0.818571</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.898571</td>\n",
       "      <td>0.798531</td>\n",
       "      <td>0.766567</td>\n",
       "      <td>0.770268</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.812857</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.904286</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.270952</td>\n",
       "      <td>0.170286</td>\n",
       "      <td>0.090429</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.812857</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.904286</td>\n",
       "      <td>0.800399</td>\n",
       "      <td>0.767409</td>\n",
       "      <td>0.770592</td>\n",
       "      <td>0.701429</td>\n",
       "      <td>0.808571</td>\n",
       "      <td>0.844286</td>\n",
       "      <td>0.884286</td>\n",
       "      <td>0.701429</td>\n",
       "      <td>0.269524</td>\n",
       "      <td>0.168857</td>\n",
       "      <td>0.088429</td>\n",
       "      <td>0.701429</td>\n",
       "      <td>0.808571</td>\n",
       "      <td>0.844286</td>\n",
       "      <td>0.884286</td>\n",
       "      <td>0.792541</td>\n",
       "      <td>0.763159</td>\n",
       "      <td>0.767439</td>\n",
       "      <td>0.682857</td>\n",
       "      <td>0.795714</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.682857</td>\n",
       "      <td>0.265238</td>\n",
       "      <td>0.167143</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.682857</td>\n",
       "      <td>0.795714</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.780539</td>\n",
       "      <td>0.748831</td>\n",
       "      <td>0.753381</td>\n",
       "      <td>0.654286</td>\n",
       "      <td>0.772857</td>\n",
       "      <td>0.805714</td>\n",
       "      <td>0.847143</td>\n",
       "      <td>0.654286</td>\n",
       "      <td>0.257619</td>\n",
       "      <td>0.161143</td>\n",
       "      <td>0.084714</td>\n",
       "      <td>0.654286</td>\n",
       "      <td>0.772857</td>\n",
       "      <td>0.805714</td>\n",
       "      <td>0.847143</td>\n",
       "      <td>0.751339</td>\n",
       "      <td>0.720615</td>\n",
       "      <td>0.726238</td>\n",
       "      <td>0.654286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.425800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.708571</td>\n",
       "      <td>0.822857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.708571</td>\n",
       "      <td>0.274286</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.708571</td>\n",
       "      <td>0.822857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.804594</td>\n",
       "      <td>0.774084</td>\n",
       "      <td>0.777673</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.858571</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.273810</td>\n",
       "      <td>0.171714</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.858571</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.806049</td>\n",
       "      <td>0.776071</td>\n",
       "      <td>0.779668</td>\n",
       "      <td>0.712857</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.855714</td>\n",
       "      <td>0.884286</td>\n",
       "      <td>0.712857</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.171143</td>\n",
       "      <td>0.088429</td>\n",
       "      <td>0.712857</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.855714</td>\n",
       "      <td>0.884286</td>\n",
       "      <td>0.798566</td>\n",
       "      <td>0.770941</td>\n",
       "      <td>0.775408</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.801429</td>\n",
       "      <td>0.844286</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.267143</td>\n",
       "      <td>0.168857</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.801429</td>\n",
       "      <td>0.844286</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.785004</td>\n",
       "      <td>0.754659</td>\n",
       "      <td>0.759389</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.775714</td>\n",
       "      <td>0.812857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.258571</td>\n",
       "      <td>0.162571</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.775714</td>\n",
       "      <td>0.812857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.758444</td>\n",
       "      <td>0.726935</td>\n",
       "      <td>0.732292</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.371900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.711429</td>\n",
       "      <td>0.824286</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.711429</td>\n",
       "      <td>0.274762</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.711429</td>\n",
       "      <td>0.824286</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.805655</td>\n",
       "      <td>0.775499</td>\n",
       "      <td>0.779089</td>\n",
       "      <td>0.712857</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.898571</td>\n",
       "      <td>0.712857</td>\n",
       "      <td>0.273333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.089857</td>\n",
       "      <td>0.712857</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.898571</td>\n",
       "      <td>0.804871</td>\n",
       "      <td>0.774910</td>\n",
       "      <td>0.778638</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.855714</td>\n",
       "      <td>0.884286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.171143</td>\n",
       "      <td>0.088429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.855714</td>\n",
       "      <td>0.884286</td>\n",
       "      <td>0.799296</td>\n",
       "      <td>0.771901</td>\n",
       "      <td>0.776334</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.801429</td>\n",
       "      <td>0.844286</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.267143</td>\n",
       "      <td>0.168857</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.801429</td>\n",
       "      <td>0.844286</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.785433</td>\n",
       "      <td>0.755187</td>\n",
       "      <td>0.759970</td>\n",
       "      <td>0.661429</td>\n",
       "      <td>0.777143</td>\n",
       "      <td>0.818571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.661429</td>\n",
       "      <td>0.259048</td>\n",
       "      <td>0.163714</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.661429</td>\n",
       "      <td>0.777143</td>\n",
       "      <td>0.818571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.759557</td>\n",
       "      <td>0.728328</td>\n",
       "      <td>0.733770</td>\n",
       "      <td>0.661429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/5 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/5 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/5 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/5 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start training, the model will be automatically saved to the hub and the output directory\n",
    "trainer.train()\n",
    " \n",
    "# save the best model\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825f3797-7e95-40a4-aa01-6867b2343fe5",
   "metadata": {},
   "source": [
    "The training with Flash Attention (SDPA) for 4 epochs on 6.3k samples took less than 4 mins on a 3090. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b07309-8e51-48b7-a871-37254dea945c",
   "metadata": {},
   "source": [
    "### Evaluate fine-tuned model against baseline\n",
    "\n",
    "We evaluated our model during training, but we also want to evaluate it against our baseline at the end. We use the same InformationRetrievalEvaluator to evaluate the performance of our model on a given set of queries and corpus set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef597ef9-c103-4809-a096-03fac0d8b74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_768_cosine_ndcg@10: 0.804975867626354\n",
      "dim_512_cosine_ndcg@10: 0.8051485851636322\n",
      "dim_256_cosine_ndcg@10: 0.7983234053795578\n",
      "dim_128_cosine_ndcg@10: 0.7847019509468028\n",
      "dim_64_cosine_ndcg@10: 0.7596781274632667\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    " \n",
    "fine_tuned_model = SentenceTransformer(\n",
    "    args.output_dir, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "results = evaluator(fine_tuned_model)\n",
    " \n",
    "# Print the main score\n",
    "for dim in matryoshka_dimensions:\n",
    "    key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "    print(f\"{key}: {results[key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b219e8-bec9-44ab-ad88-6adc18d01b60",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Embedding models are crucial for successfull RAG applications, since if you don't retrieve the right context you can't generate the right answer. Customizing embedding models for domain-specific data can improve retrieval performance significantly compared to using general knowledge models. Fine-tuning embedding models has become highly accessible, and using synthetic data generated by LLMs, one can easily customize models for specific needs, resulting in substantial improvements.\n",
    "\n",
    "Our results show that fine-tuning can boost performance by ~7% with only 6.3k sample. The training took 3 minutes on a consumer size GPU and by leveraging modern techniques like Matryoshka Representation Learning we achieved over 99% performance retention with 6x storage reduction and efficiency gains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
